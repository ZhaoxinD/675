SELECT COUNT(*) FROM Posts WHERE Posts.ViewCount > 41425
So we break down the ViewCount into 5 parts, and combined the data afterwards.
select top 50000 * from posts where posts.ViewCount > 41425 order by
posts.ViewCount DESC
select top 50000 * from posts where posts.ViewCount < 127755 order by
posts.ViewCount DESC
select top 50000 * from posts where posts.ViewCount < 74790 order by
posts.ViewCount DESC
select top 50000 * from posts where posts.ViewCount < 53349 order by
posts.ViewCount DESC
select top 1000 * from posts where posts.ViewCount < 41429 order by posts.ViewCount
DESC


mount -t vboxsf big_data /home/usr/data #to build the connection between the
virtual machine and local machine


A= LOAD 'Query_Results.csv' using PigStorage(',') AS (Id:int, PostTypeId:int,
AcceptedAnswerId:int, ParentId:int, CreationDate:datetime, DeletionDate:datetime,
Score:int, ViewCount:int, OwnerUserId:int, OwnerDisplayName:chararray,
LastEditorUserId:int, LastEditorDisplayName:chararray, LastEditDate:datetime,
LastActivityDate:datetime, Title:chararray, Tags:chararray, AnswerCount:int,
CommentCount:int, FavoriteCount:int, ClosedDate:datetime,
CommunityOwnedDate:datetime, ContentLicense:chararray);
B= FOREACH A GENERATE
Id,Score,ViewCount,OwnerUserId,OwnerDisplayName,Title,Tags;
STORE B INTO 'final_queries' using PigStorage(',');

create external table if not exists hivetable (Id int, Score int, ViewCount int,
OwnerUserId int, OwnerDisplayName string, Title string, Tags string) ROW FORMAT
DELIMITED FIELDS TERMINATED BY ',';
load data local inpath '/home/hangyu_tian/data.csv' overwrite into table
hivetable;

SELECT Title, Score from hivetable order by Score desc limit 10;

create table user_table as select ownerUserId as A, SUM(Score) as B from
hivetable
group by ownerUserId;

select * from user_table order by B desc limit 10;

select COUNT(OwnerUserId) from mytable where Title like '%cloud%'

create table tf_table as select ownerUserId, Title from hivetable order by Score
desc limit 10;
create view exploded as select ownerUserId, word from tf_table LATERAL VIEW
explode(tokenize(Title, True)) t as word where not is_stopword(word);
create view term_frequency as select ownerUserid, word, freq from (select
ownerUserId,
tf(word) as word2freq from exploded group by ownerUserId) t LATERAL VIEW
explode(word2freq) t2 as word, freq;
create or replace view document_frequency as select word, count(distinct
ownerUserId) docs from exploded group by word;
select count(ownerUserId) from tf_table;
set hivevar:n_docs=10;
create or replace view tfidf as select tf.ownerUserId, tf.word, tfidf(tf.freq,
df.docs, ${n_docs}) as tfidf from term_frequency tf JOIN document_frequency df ON
(tf.word = df.word) order by tfidf desc;
